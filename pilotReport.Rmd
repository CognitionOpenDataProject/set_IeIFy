---
title: "COD Reproducibility Report"
output:
  html_document:
    toc: true
    toc_float: true
---

#### Article ID: IeIFy
#### Pilot: Sara Kessler
#### Start date: 03/20/2017
#### End date: 03/20/2017   

-------

#### Methods summary: 

Arnold, et al. (2016) investigate whether temporal information from previous experiences is retained in mental simulations, hypothesizing that "simulated episodes contain temporal aspects of the experiences  the simulation is recapitulated from, albeit in a compressed form" (Arnold et al., 2016, p. 15). In order to investigate this question, participants were shown a video from a first person perspective of a walk around the perimeter of a virtual city which had five visually salient landmarks in it. The landmarks were pointed out and introduced. Participants then underwent 20 encoding trials in which they had to navigate between two landmarks, as quickly as possible. Finally, the participants had a simulation phase where they shown images of two landmarks and then had to close their eyes and mentally simulate navigating from one to the other, imagining their route in detail.  They were asked to use the quickest route possible, not necessarily one they had used in the encoding phase. After the mental simulation they answered a questionnaire to probe qualitative aspects of the simulations. Then they had to navigate the actual route in the virtual city as quickly as possible, followed by another questionnaire about how well they navigated the route, and how closely their simulation matched the actual navigation. There were 10 routes in the simulation phase. 

------

#### Target outcomes: 
The target outcomes for this reproduction are outlined in Section 2.1.3 of Arnold et al. (2016):

> Inspection of the route time histogram from the simulation phase revealed a number of trials in which participants became “lost” (see Fig. S1), which skewed the distribution. To control for this, we calculated the difference between the optimal route time and the observed route time (mean difference score = 14.27 s; SD = 19.49). The resulting distribution was then used to remove trials in the top 25% of difference scores across participants (75% quartile = 21.66 s, 70 trials removed). This filtering strategy allowed for retention of variance in route time, while excluding trials that took approximately double the optimal route time (M = 24.85 s, SD = 7.16). See Supplemental Sections 1.2.3–1.2.4 and Fig. S2 for a comparison using an alternative filter of 3 standard deviations. Route performance on the filtered data set of 210 trials was near the optimal route time (mean difference score = 5.93 s, SD = 3.54).

> Next, we assessed the relationship between simulation time (M = 14.41, SD = 11.21) and route navigation time (M = 35.81, SD = 9.25; see Fig. 2a–b). Simulation times were first mean-centered for each participant, providing a more precise estimate of coefficients as it minimizes variance in simulation time due to individual differences in overall temporal compression rate. We found a statistically significant positive correlation between the time it took a participant to subsequently navigate the route and the time it took them to mentally simulate it (r(208) = 0.30, p < 0.001, R2 = 0.09, Fig. 3C). We also found a significant positive correlation between simulation time and route distance (r(208) = 0.29, p < 0.001, R2 = 0.08); however, route time and distance for each trial were highly collinear (r(208) = 0.97, p < 0.001, R2 = 0.94). As such, the remainder of the analysis focuses on route time, which accounts for variance in non-movement related processes (e.g. making decisions at turning points) that are not represented in the distance measure. Our correlation reported here between simulation and route time is consistent with past findings from Kosslyn et al. (1978) who showed a correlation between the time it took participants to mentally scan between different locations on a map of an island and the physical distance between them.  (Arnold et al. 2016, p. 17)

------

```{r global_options, include=FALSE}
knitr::opts_chunk$set(echo=TRUE, warning=FALSE, message=FALSE)
```

## Step 1: Load packages

```{r}
library(tidyverse) # for data munging
library(knitr) # for kable table formating
library(haven) # import and export 'SPSS', 'Stata' and 'SAS' Files
library(readxl) # import excel files
library(CODreports) # custom report functions
sem <- function(x) {sd(x, na.rm=TRUE) / sqrt(length(x))}
ci95 <- function(x) {sem(x) * 1.96}
```

## Step 2: Load data

```{r}
d_raw <- read_csv("data/data3.csv")
d_filtered <- read_csv("data/data1.csv")
```

## Step 3: Tidy data

```{r}
#The optimal times were copied out of data_1 for subject 26 in group 1 who had none of their trials excluded
opt_times <- d_filtered%>%
  filter(Group == 1, Participant ==26) %>%
  select(Optimal)
num_subs <- length(unique(d_raw$Participant))

d_tidy <- d_raw %>%
  rename(trial_num = X1, 
         obs_route_time = Path_Time, 
         distance = Distance, 
         sim_time = Sim_Time, 
         subid = Participant) %>%
  select(subid, trial_num, obs_route_time, distance, sim_time)%>%
  mutate(optimal_route_time = rep(opt_times$Optimal,num_subs))
```

## Step 4: Run analysis

### Pre-processing



```{r}
d <- d_tidy %>%
  mutate(diff = obs_route_time - optimal_route_time)

summary(d$diff)
mean_diff = mean(d$diff)
sd_diff = sd(d$diff)
sd_diff

compareValues(reportedValue = 14.27, obtainedValue = mean_diff)
compareValues(reportedValue = 19.49, obtainedValue = sd_diff)
```
These summary statistics are the same as are reported in the analysis script in the supplementary materials, but differ substantially from the values reported in the paper.


```{r}
ggplot(d, aes(x=diff)) +
    geom_histogram(binwidth=20, colour="black", fill="white")

```


![Supplementary Figure 1 - Distribution of difference scores](images/fig_s1.png)


The distribution does not seem to quite match, between my figure and the one in the paper, and although the outliers are similar, the first two bins are different. The code in the supplementary material paper seems to indicate that they also used bins of 20.

>sns.distplot(p_data.Diff.dropna(), kde=False, bins=20);

```{r}
#get rid of the top 25% of difference times
top_quant = quantile(d$diff, .75)
d <- d%>%
  filter(d$diff < top_quant)

```

The top quantile matches what was reported in the paper, and the same number of trials were filtered out using this criterion. However, it does not match what was reported in the text of the supplemental materials (14.95 s), though it does match the number in the print-out of the code calculating it.
```{r}
compareValues(reportedValue = 14.95, obtainedValue = top_quant)
```


### Descriptive statistics

```{r}
mean_opt = mean(opt_times$Optimal)
sd_opt = sd(opt_times$Optimal)


compareValues(reportedValue = 7.15, obtainedValue = sd_opt)
```
The mean and standard deviation of the route time are reported twice in the paper, once on page 16 and once on page 17. On the former the SD is reported as 7.15 and on the latter as 7.16. The latter is the result I found.

```{r}
mean_diff_filt = mean(d$diff)
sd_diff_filt = sd(d$diff)

compareValues(reportedValue = 5.93, obtainedValue = mean_diff_filt)
compareValues(reportedValue = 3.54, obtainedValue = sd_diff_filt)
```
There is a discrepancy in the mean difference scores reported post filtering in the paper, and those I found, as well as in the SD.

```{r}
mean_sim_time = mean(d$sim_time)
mean_sim_time
sd_sim_time = sd(d$sim_time)
sd_sim_time

mean_nav_time = mean(d$obs_route_time)
mean_nav_time
sd_nav_time = sd(d$obs_route_time)
sd_nav_time
```

The reported mean and SD for simulation time and route navigation times match those that I found here.

```{r}
d_g1<-d%>%
  mutate(group = 1) %>%
  group_by(group) %>%
  summarize(mean = mean(obs_route_time),
            cis = ci95(obs_route_time))
ggplot(data=d_g1, aes(x=group, y=mean)) +
    geom_bar(stat="identity", fill="#FF6600") +
    geom_errorbar(aes(ymin=mean-cis, ymax=mean+cis),
                  width=.2, position=position_dodge(.9)) + xlab("Medium") + ylab("Seconds") + ggtitle("Route Time") +
  scale_x_discrete(breaks=NULL)
```

```{r}
d_g2<-d%>%
  mutate(group = 1) %>%
  group_by(group) %>%
  summarize(mean = mean(sim_time),
            cis = ci95(sim_time))
ggplot(data=d_g2, aes(x=group, y=mean)) +
    geom_bar(stat="identity", fill="#FF6600") +
    geom_errorbar(aes(ymin=mean-cis, ymax=mean+cis),
                  width=.2, position=position_dodge(.9)) + xlab("Medium") + ylab("Seconds") + ggtitle("Simulation Time") +
  scale_x_discrete(breaks=NULL)
```



![Figure 2](images/fig_2.png)

My figures seem to match the middle (orange) bars of Figures 2a and 2b.


```{r}
#mean center the simulation times for each participant then rejoin them with the rest of the data.
d_centered <- d%>%
  group_by(subid)%>%
  mutate(centered_sim_time = scale(sim_time, center = T, scale = F)[,1])%>%
  group_by(subid, trial_num, add = FALSE) %>%
  summarize(centered_sim_time = mean(centered_sim_time))

d <- right_join(d, d_centered)


```


### Inferential statistics

```{r}
cor.test(d$obs_route_time, d$centered_sim_time)

(cor(d$obs_route_time, d$centered_sim_time))^2
```
Using the centered simulation times for each participant, I found the same significant positive correlation between the time it took a participant to subsequently navigate the route and the time it took them to mentally simulate it as was found in the paper.

```{r}
cor.test(d$centered_sim_time, d$distance)

(cor(d$centered_sim_time, d$distance))^2
```

Similarly, as in the paper, I too found a significant positive correlation between the centered simulation times and the route distance, with the same figures as found in the paper.

```{r}
cor.test(d$obs_route_time, d$distance)

(cor(d$obs_route_time, d$distance))^2
```

Additionally, as in the paper, the route navigation times and the route distance are highly colinear, therefore route time is used throughout the rest of the analysis.

```{r}
d<- d %>%
  mutate(compression_rate = sim_time/obs_route_time)
mean_comp = mean(d$compression_rate)
mean_comp
sd_comp = sd(d$compression_rate)
sd_comp


```

The compression rate was calculated as the ratio of the (uncentered) simulation times to the route time for each trial. I found the same mean and SD compression rate as found by Arnold et al. (2016), supporting their hypothesis that 

>"participants simulated routes at around 2.39 times the rate the subsequently navigate them." (Arnold et al., 2016, p. 17)


```{r}
d_g3<-d%>%
  mutate(group = 1) %>%
  group_by(group) %>%
  summarize(mean = 1/mean(compression_rate),
            cis = ci95(compression_rate))
ggplot(data=d_g3, aes(x=group, y=mean)) +
    geom_bar(stat="identity", fill="#FF6600") +
    geom_errorbar(aes(ymin=mean-cis, ymax=mean+cis),
                  width=.2, position=position_dodge(.9)) + xlab("Medium") + ylab("Factor") + ggtitle("Compression Rate") +
  scale_x_discrete(breaks=NULL)
```


![Figure 2](images/fig_2.png)

I'm not sure exactly what the error bar is representing in Figure 2c, since the calculation was 1/compression rate. The bar itself though that I generated matches the middle (orange) bar in Figure 2c.


## Step 5: Conclusion

```{r}
codReport(Report_Type = 'pilot',
          Article_ID = 'IeIFy', 
          Insufficient_Information_Errors = 0,
          Decision_Errors = 0, 
          Major_Numerical_Errors = 5, 
          Minor_Numerical_Errors = 1)
```

I found that the inferential statistics were congruent with those reported in the paper. However, there were inconsistencies with the descriptive statistics reported in the paper. The mean and SD of the difference score between the optimal route time and the observed route time were different, as were the mean and SD of the difference score of the filtered data. These discrepancies could be related since they involve the same measure. I am not sure what might have caused the discrepancy though. Additionally the top quantile cut-off point reported in the text of the supplement was off, but that was probably calculated using a previous version of the data, and then hard coded in instead of using a variable. There was a minor discrepancy in the reporting of the SD of optimal time route earlier in the paper. Finally, it is not clear how the confidence interval in Figure 2c in the paper is determined.


```{r session_info, include=TRUE, echo=TRUE, results='markup'}
devtools::session_info()
```
